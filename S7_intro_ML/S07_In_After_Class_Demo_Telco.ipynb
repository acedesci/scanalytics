{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "S7-Full_Demo_Telco.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acedesci/scanalytics/blob/master/S7_intro_ML/S07_In_After_Class_Demo_Telco.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H797invmatYz"
      },
      "source": [
        "# Session 7: Introduction to ML - Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyTCwtrpatY1"
      },
      "source": [
        "## Demo 3: Classification on Customer Churn Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ke5yJeXbatY2"
      },
      "source": [
        "Classification using customer service churn dataset (https://www.kaggle.com/blastchar/telco-customer-churn)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvWk3rsPb5-Z"
      },
      "source": [
        "!pip install -q dtreeviz\r\n",
        "from dtreeviz.trees import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC0hkjqkatY3"
      },
      "source": [
        "import sklearn\n",
        "from sklearn import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPGEQHjP4JGL"
      },
      "source": [
        "import pandas as pd\r\n",
        "# Load transformed dataset\r\n",
        "url = 'https://raw.githubusercontent.com/acedesci/scanalytics/master/S7_intro_ML/data/Telco-Customer-Churn_dummies.csv'\r\n",
        "customer_data = pd.read_csv(url)\r\n",
        "\r\n",
        "selected_features = customer_data.columns[1:-1].values #take only column 2 until the column prior to the predicted value (the last column is the label)\r\n",
        "print(selected_features)\r\n",
        "X = customer_data[selected_features].values\r\n",
        "y = customer_data['Churn_Yes'].values\r\n",
        "customer_data.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KslAXQcRatZD"
      },
      "source": [
        "# Split into training and testing data (72/25 by default)\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OurT10YPatZH"
      },
      "source": [
        "### 1. Logistic regression model\r\n",
        "\r\n",
        "In addition to precision and recall, we can also measure the aggregate measure of both which is called F-Score (see [link](https://en.wikipedia.org/wiki/F-score)). The F-1 Score is a harmonic mean of both measures where `F-Score = 1.0`  indicates the perfect precision and recall whereas the lowest value is `F-Score = 0` which occurs when either precision or recall equals zero. F-Score score can be calculated as follows:\r\n",
        "\r\n",
        "$F_1 = \\frac{2}{\\frac{1}{Precision} + \\frac{1}{Recall}} = 2\\frac{Precision \\times Recall}{Precision + Recall}$\r\n",
        "\r\n",
        "We can use sklearn function `.f1_score(y_true, y_predict)` to calculate it (see [link](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hB2O6pxeatZI"
      },
      "source": [
        "# Run Logistic regression\n",
        "logreg = sklearn.linear_model.LogisticRegression().fit(X_train, y_train)\n",
        "\n",
        "# Print the results\n",
        "print(\"Logistic Regression: Training accuracy: {:.3f}\".format(logreg.score(X_train, y_train)))\n",
        "print(\"Logistic Regression: Testing accuracy: {:.3f}\".format(logreg.score(X_test, y_test)))\n",
        "\n",
        "# Predict the values y from the trained model on the test set\n",
        "y_predict = tree.predict(X_test)\n",
        "print(\"Logistic Regression: Precision: {:.3f}\".format(sklearn.metrics.precision_score(y_test, y_predict)))\n",
        "print(\"Logistic Regression: Recall: {:.3f}\".format(sklearn.metrics.recall_score(y_test, y_predict)))\n",
        "print(\"Logistic Regression: F1-Score: {:.3f}\".format(sklearn.metrics.f1_score(y_test, y_predict)))\n",
        "\n",
        "# We can also print out a confusion matrix\n",
        "print(sklearn.metrics.confusion_matrix(y_test, y_predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNyGfq19atZM"
      },
      "source": [
        "### 2. Decision tree model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zKObEf0o6s0"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT4g8l9datZN"
      },
      "source": [
        "# Run decision tree\n",
        "\n",
        "tree_results = pd.DataFrame(columns = ['Depth','Train-Accuracy','Test-Accuracy','Precision','Recall', 'F-Score'])\n",
        "\n",
        "for depth in range(3,10,2):\n",
        "  tree = sklearn.tree.DecisionTreeClassifier(max_depth = depth, random_state=0).fit(X_train, y_train)\n",
        "  y_predict = tree.predict(X_test)\n",
        "\n",
        "  # compute each measure and add to the new row in DataFrame\n",
        "  train_acc = tree.score(X_train, y_train)\n",
        "  test_acc = tree.score(X_test, y_test)\n",
        "  test_precision = sklearn.metrics.precision_score(y_test, y_predict)\n",
        "  test_recall = sklearn.metrics.recall_score(y_test, y_predict)\n",
        "  f_score = 2*test_precision*test_recall/(test_precision+test_recall)\n",
        "  \n",
        "  # add the results (list) to the last row in the DataFrame\n",
        "  tree_results.loc[len(tree_results)] = [depth,train_acc,test_acc,test_precision,test_recall,f_score]\n",
        "\n",
        "tree_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7StFO1AMexzH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISMYZ-LGeyN_"
      },
      "source": [
        "[link1](https://github.com/parrt/dtreeviz) and [link2](https://colab.research.google.com/github/parrt/dtreeviz/blob/master/notebooks/examples.ipynb) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYKoNxzPcTWj"
      },
      "source": [
        "viz = dtreeviz(tree, X_train, y_train, target_name=\"Churn\", feature_names=selected_features, max_X_features_LR = 2, max_X_features_TD = 2)\r\n",
        "viz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5ClQBrFn8IV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ru-lyENidBn5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QL3zoNdbbab5"
      },
      "source": [
        "#### Explore feature importance and tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_GEslOgatZY"
      },
      "source": [
        "print(selected_features)\n",
        "print(tree.feature_importances_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS4jHtuOatZf"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12,12))\n",
        "sklearn.tree.plot_tree(tree, feature_names=selected_features, fontsize=10, max_depth=2)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiV1Pm6SatZj"
      },
      "source": [
        "### 3. Evaluation - calculate precision and recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lY8BzUCdatZk"
      },
      "source": [
        "Calculate precision and recall for the model recently fitted (either logistic regression or decision tree)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbnNL7GpatZk"
      },
      "source": [
        "# calculate precision and recall\n",
        "\n",
        "y_predict = logreg.predict(X_test) #use this for logistic regression \n",
        "# y_predict = tree.predict(X_test) #use this for decision tree\n",
        "\n",
        "print(\"Precision score: {:.3f}\".format(sklearn.metrics.precision_score(y_test, y_predict)))\n",
        "print(\"Recall score: {:.3f}\".format(sklearn.metrics.recall_score(y_test, y_predict)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLhjpn4matZn"
      },
      "source": [
        "Plot precision-recall curve (see https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html#sphx-glr-auto-examples-model-selection-plot-precision-recall-py)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm-LMn2KatZo"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_prob = logreg.decision_function(X_test) #use this for logistic regression\n",
        "# y_prob = tree.predict_proba(X_test)[:,1]  #use this for decision tree\n",
        "\n",
        "precision, recall, thresholds = sklearn.metrics.precision_recall_curve(y_test, y_prob)\n",
        "\n",
        "plt.figure()\n",
        "plt.step(recall, precision)\n",
        "average_precision = sklearn.metrics.average_precision_score(y_test, y_prob)\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.title('Average precision score: AP={0:0.2f}'.format(average_precision))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6A6XX4OsatZr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
