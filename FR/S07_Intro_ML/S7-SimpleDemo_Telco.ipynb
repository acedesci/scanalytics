{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "S7-SimpleDemo_Telco.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acedesci/scanalytics/blob/master/EN/S07_Intro_ML/S7-SimpleDemo_Telco.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H797invmatYz"
      },
      "source": [
        "# Session 7: Introduction to ML - Classification\n",
        "---\n",
        "*Created by Yossiri Adulyasak*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyTCwtrpatY1"
      },
      "source": [
        "## Step-by-step simple demo based on Classification on Customer Churn Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cS5YfcZHddR"
      },
      "source": [
        "Classification using customer service churn dataset (https://www.kaggle.com/blastchar/telco-customer-churn). This dataset has been preprocessed to create dummy variables. We will only use part of the variables and datapoints in this example. **This simple demo shows a step-by-step analysis of a sliced dataset which can be easily reviewed with detailed markdown comments for this case.** For the full-scale run, you can modify the code to allow the models to train on the full dataset.\n",
        "\n",
        "In this first step, we will load sklearn library, which is a common library used in machine learning. Please see: https://scikit-learn.org/stable/getting_started.html for reference. The code \"sklearn.__version__\" simply shows the version of sklearn we are using."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC0hkjqkatY3"
      },
      "source": [
        "import sklearn\n",
        "from sklearn import *\n",
        "sklearn.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYyh9qxZIE13"
      },
      "source": [
        "### **Block 1**: data input\n",
        "\n",
        "First, we will load the data input which is in the csv format. This data input is available on the URL indicated in the codes (there is no need to download it to your machine but you can follow the link to download it if you want to). We will print out the first 5 rows to review. \n",
        "\n",
        "In this dataset, the first column is the ID of the customer whereas the subsequent columns, except the last one, describe the input data which are associated with each customer (e.g., for the first customer, he is not a *SeniorCitizen*, has a *tenure* of 1 month, and his *MonthlyCharges* is $29.85, etc.). The last column is the label indicating if his customer has not churned (*Churn_Yes* = 0)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZPBpYfIatY_"
      },
      "source": [
        "import pandas as pd\n",
        "# Load transformed dataset\n",
        "url = 'https://raw.githubusercontent.com/acedesci/scanalytics/master/EN/S07_Intro_ML/data/Telco-Customer-Churn_dummies.csv'\n",
        "customer_data = pd.read_csv(url)\n",
        "customer_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVglUK-QKnG0"
      },
      "source": [
        "For simplicity, we will cut only the first 20 customer IDs for our demo. This is only for the sake of presentation and you should run the analysis in the full dataset in practice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b028tdVXK44j"
      },
      "source": [
        "customer_data = customer_data.loc[:20]\n",
        "customer_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Is4-vR1J6zu"
      },
      "source": [
        "### **Block 2**: Feature preparation\n",
        "\n",
        "This block is supposed to be for feature engineering. Since all the features are already prepared and are in numerical format, we will not do the feature engineering/transformation here. We will only take 3 input variables to be used in our model in this case (see \"selected_features\" below).\n",
        "\n",
        "The input variables are then assigned to *X* and the target variable (column 'Churn_Yes') is then assigned to *y*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8vwOYsAKCrZ"
      },
      "source": [
        "selected_features = ['tenure', 'TotalCharges', 'InternetService_Fiber optic']\n",
        "print(selected_features)\n",
        "X = customer_data[selected_features]\n",
        "y = customer_data['Churn_Yes']\n",
        "\n",
        "print(\"Input variables (X):\\n\"+str(X))\n",
        "print(\"Predicted variable (y):\\n\"+str(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cricffn8MH0m"
      },
      "source": [
        "You can see from the above results that the first data point \"[1.00000e+00 2.98500e+01 0.00000e+00]\" corresponds to the first customer (ID 0), and the second one corresponds to the second customer and so on. The first predicted value is the 'label' which corresponds to the first data point and indicates that the first customer did not churn (y = 0). There are 20 data points in total (since we take only the first 20 data points)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncv1sPmcOCXV"
      },
      "source": [
        "### Splitting data for training and testing process ###\n",
        "\n",
        "Since we want to measure the performance of the model for prediction task, we must perform a cross-validation process in order to evaluate how the model performs on the data it has not seen in the training (or model parameter fitting) process. This will allow us to see how the model would perform once we use it in prediction which predicts the results based on the new data points where the labels (prediced values) are still not available.\n",
        "\n",
        "The codes below will randomly split the data into 75% for training and 25% in testing. We also print out the split data to review which data points below to the training set, and which data points belong to the testing set.\n",
        "\n",
        "In order to do this, we use sklearn function *model_selection.train_test_split(X, y)* (see https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) which takes the input data X and label y. Since this function will split the data points randomly, we also indicate \"random_state=0\" so that we can reproduce the same result (in practice, this would not be necessary)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KslAXQcRatZD"
      },
      "source": [
        "# Split into training and testing data (75/25 by default)\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state=0)\n",
        "\n",
        "print(X_train)\n",
        "print(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwgWEWR4P9Id"
      },
      "source": [
        "# Here is the training set:\n",
        "print(\"Number of data points in training set: \"+str(len(y_train)))\n",
        "print(\"Training X:\\n\"+str(X_train))\n",
        "print(\"Training y:\\n\"+str(y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6u6I01eQBEn"
      },
      "source": [
        "# Here is the testing set:\n",
        "print(\"Number of data points in testing set: \"+str(len(y_test)))\n",
        "print(\"Testing X:\\n\"+str(X_test))\n",
        "print(\"Testing y:\\n\"+str(y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OurT10YPatZH"
      },
      "source": [
        "### **Block 3**: Model\n",
        "\n",
        "In this block, we will choose the models to be used for prediction. Only the training set will be used in this step (and the testing set will be used in cross-validation). We will consider two models, i.e., logistic regression and decision tree."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLZhNt44RVie"
      },
      "source": [
        "### 3.1 Logistic regression model\n",
        "\n",
        "Here we will prepare the object of the model by calling the function which corresponds to the model we choose. You can simply call the code below *sklearn.linear_model.LogisticRegression()* to create an object of logistic regression which we name as *logreg*\n",
        "\n",
        "See https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html for more information about this function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY73boV1RUDM"
      },
      "source": [
        "logreg = sklearn.linear_model.LogisticRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4tPR7JERS7l"
      },
      "source": [
        "### 3.2 Classification tree model\n",
        "\n",
        "Now we also prepare an object for classification tree using *sklearn.tree.DecisionTreeClassifier()* to create an object of logistic regression which we name as *tree*. Note that the algorithm uses a random initialization so we also put *random_state=0* to ensure that we can reproduce the result.\n",
        "\n",
        "See https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html for more information about this function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOmUXypsSkX2"
      },
      "source": [
        "tree = sklearn.tree.DecisionTreeClassifier(random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNSzsYI6Sm2f"
      },
      "source": [
        "### Running ML algorithm to fit the model\n",
        "\n",
        "Now we need to fit the models (both logistic regression and classification tree) by using the training dataset. This step can be done by calling the method *model_object.fit(X,y)* on the object of the model we already created. The model will estimate the parameters from the input variables X and label y in the training set (75% of data points).\n",
        "\n",
        "First we train the logistic regression model using the training set. We also print out the accuracy level from the model for the training set to see how the model performs in this training set (note: this is NOT cross-validation).\n",
        "\n",
        "The method *model_object.score(X, y)* will take the data input X to perform a prediction (or estimation) and then it will compare the result of the preduction to the known label *y*. You can review the documentation of the model (the links under 3.1 and 3.2) for more information about the methods fit(), score(), and other methods of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDIbKoZATHa_"
      },
      "source": [
        "# Train Logistic regression\n",
        "logreg.fit(X_train, y_train)\n",
        "print(\"Logistic Regression: Training accuracy: {:.3f}\".format(logreg.score(X_train, y_train)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgqsFTKUTKII"
      },
      "source": [
        "The results indicated the accuracy on this set = 86.7%.\n",
        "\n",
        "If you want to see the predicted result for each customer (in the training set), you can call the method *predict()* and compare it with the labels to see which customers (again, in the training set) were predicted correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_pFWQkJW0Pn"
      },
      "source": [
        "print(\"Predicted X_train:\\n\"+str(logreg.predict(X_train)))\n",
        "print(\"Actual y_train:\\n\"+str(y_train.values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtASv9ZBXpdv"
      },
      "source": [
        "We do the same for classification tree."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaiuoTxITJh_"
      },
      "source": [
        "# Train classification tree\n",
        "tree.fit(X_train, y_train)\n",
        "print(\"Classification tree: Training accuracy: {:.3f}\".format(tree.score(X_train, y_train)))\n",
        "\n",
        "print(\"Predicted X_train:\\n\"+str(tree.predict(X_train)))\n",
        "print(\"Actual y_train:\\n\"+str(y_train.values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRSmzagETejB"
      },
      "source": [
        "### **Block 4**: Validation\n",
        "\n",
        "Now we have trained the two models using the training sets. The cross-validation is the key step to evaluate if the models will still perform well on the data points they haven't seen before. In order to do this, we can simply call the *score()* method but using the test set instead of the training set. In addition, we also calculate precision and recall. The details of *score()*,* precision()* and *recall()* methods are in the corresponding documentation page of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hB2O6pxeatZI"
      },
      "source": [
        "# Measure the out-of-sample performance of the logistic regression model\n",
        "\n",
        "y_predict = logreg.predict(X_test)\n",
        "print(\"Logistic Regression:\")\n",
        "print(\"   Predicted X_test:\"+str(y_predict))\n",
        "print(\"   Actual y_test:\"+str(y_test.values))\n",
        "print(\"   Testing accuracy: {:.3f}\".format(logreg.score(X_test, y_test)))\n",
        "print(\"   Precision score: {:.3f}\".format(sklearn.metrics.precision_score(y_test, y_predict)))\n",
        "print(\"   Recall score: {:.3f}\".format(sklearn.metrics.recall_score(y_test, y_predict)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGIROYsJkY6Z"
      },
      "source": [
        "You can see that the model does not generalize well when testing against the data is hasn't seen before. The testing accuracy is 66.7% whereas recall is only 33.3%.\n",
        "\n",
        "Now we test the classification tree model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNFPV_wbklO6"
      },
      "source": [
        "y_predict = tree.predict(X_test)\n",
        "print(\"Classification Tree:\")\n",
        "print(\"   Predicted X_test:\"+str(y_predict))\n",
        "print(\"   Actual y_test:\"+str(y_test.values))\n",
        "print(\"   Testing accuracy: {:.3f}\".format(tree.score(X_test, y_test)))\n",
        "print(\"   Precision score: {:.3f}\".format(sklearn.metrics.precision_score(y_test, y_predict)))\n",
        "print(\"   Recall score: {:.3f}\".format(sklearn.metrics.recall_score(y_test, y_predict)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0KEuKJskukC"
      },
      "source": [
        "which gives even worse results, and only 33.3% of accuracy is achieved. However, please keep in mind that this model was trained and tested on very small data set. You can run Demo 3 to review the results on the full data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNyGfq19atZM"
      },
      "source": [
        "### Getting the insights in the models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNIrV0iwllBa"
      },
      "source": [
        "The logistic regression model can provide you the coefficeints of the linear function of the fitted model. You can obtain those attributes from the trained model (object). This is also described in the documentation page of the model. The codes below show how such outputs can be obtained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT4g8l9datZN"
      },
      "source": [
        "# Obtain the coefficients of the logistic regression model\n",
        "print(\"intercept\"+str(logreg.intercept_))\n",
        "print(\"coefficients:\"+str(logreg.coef_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QL3zoNdbbab5"
      },
      "source": [
        "For the classification tree model, the main output is *feature_importances_* which indicate the relative importance score of each feature used in the model. We can explore feature importance using the codes below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_GEslOgatZY"
      },
      "source": [
        "print(\"List of features: \"+ str(selected_features))\n",
        "print(\"Feature importance: \"+ str(tree.feature_importances_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yStpfBAinc8X"
      },
      "source": [
        "We can also vitualize the classification tree using the codes below (note: the *max_depth* parameter will control the size of the displayed tree. We would not be able to visualize a very big tree so you can change the depth to display only a certain number of layers of the tree)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS4jHtuOatZf"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12,12))\n",
        "sklearn.tree.plot_tree(tree, feature_names=selected_features, fontsize=10, max_depth=4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLhjpn4matZn"
      },
      "source": [
        "### Precision-recall curve\n",
        "\n",
        "Since logistic regression and decision tree use a threshold (by default = 0.5) to indicate if the predicted probability implies the label 1 (when probability >= 0.5) or label 0 (when probability < 0.5). Changing this threshold will also change the result. In particular, when we lower the probability, the model will predict more positive case (label = 1) and thus this will increase the recall score (as we successfully capture more positive labels). However, at the same time, we will generally lower the precision score (as more false positive can occur). \n",
        "\n",
        "\n",
        "You can obtain the probabilities associated with each label (0 or 1) for each data point by calling the function `.predict_proba(X)` [link](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict_proba). The precision-recall curve will show the trade-off between these two measures. For more information on the plot of the precision-recall curve, you can review https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html. The output `thresholds` provides the set of new different thesholds of the probability used to determine the positive level.\n",
        "\n",
        "The codes below provide the plot for the precision-recall of the logistic regression model. I would encourage you to try it on the full data set to better see the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm-LMn2KatZo"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# obtain the probability associated with label 1\n",
        "# since predict_proba return the probabilities for both classes, \n",
        "# we only take the second one (probability for label 1) by adding [:, 1] to slice them \n",
        "y_prob = logreg.predict_proba(X_test)[:, 1] # use this for logistic regression\n",
        "# y_prob = tree.predict_proba(X_test)[:, 1] # use this for tree (the result on the test is bad for this one)\n",
        "\n",
        "\n",
        "precision, recall, thresholds = sklearn.metrics.precision_recall_curve(y_test, y_prob)\n",
        "pred_recal_df = pd.DataFrame()\n",
        "pred_recal_df['Threshold'] = [0] + list(thresholds) # the first threshold is zero but we need to add manually\n",
        "pred_recal_df['Precision'] = precision\n",
        "pred_recal_df['Recall'] = recall\n",
        "display(pred_recal_df)\n",
        "\n",
        "plt.figure()\n",
        "plt.step(recall, precision)\n",
        "average_precision = sklearn.metrics.average_precision_score(y_test, y_prob)\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.title('Average precision score: AP={0:0.2f}'.format(average_precision))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}