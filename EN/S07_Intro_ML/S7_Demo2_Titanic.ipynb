{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"S7_Demo2_Titanic.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github","colab_type":"text"},"source":["<a href=\"https://colab.research.google.com/github/acedesci/scanalytics/blob/master/S7_intro_ML/S7_Demo2_Titanic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"yYWkiajyT7dy","colab_type":"text"},"source":["# Session 7: Introduction to ML - Classification"]},{"cell_type":"markdown","metadata":{"id":"V4W6ZNmfT7dz","colab_type":"text"},"source":["## Demo 2: Classification on Toy Dataset 2 (Titanic)"]},{"cell_type":"markdown","metadata":{"id":"HtkcV00mT7d1","colab_type":"text"},"source":["Classification using the Dataset from Kaggle (https://www.kaggle.com/c/titanic/data). The data file is provided to you and please put the folder \"data_titanic\" in the same folder as this jupyter notebook."]},{"cell_type":"code","metadata":{"id":"pLD9AVYPT7d3","colab_type":"code","colab":{}},"source":["import sklearn\n","from sklearn import *\n","sklearn.__version__"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wMjSEQBkT7d9","colab_type":"code","colab":{}},"source":["import pandas #we also need pandas package here to load the csv data\n","\n","# Load dataset\n","url = 'https://raw.githubusercontent.com/acedesci/scanalytics/master/S7_intro_ML/data/titanic_train.csv'\n","data = titanic_data = pandas.read_csv(url)\n","data.head(5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9_VpPqSjT7eB","colab_type":"code","colab":{}},"source":["le_gender = sklearn.preprocessing.LabelEncoder()\n","data['binary_gender'] = le_gender.fit_transform(titanic_data['Sex'].values)\n","selected_features = ['Pclass','Age', 'SibSp', 'Parch', 'Fare','binary_gender']\n","X = data[selected_features].fillna(0).values\n","y = data['Survived'].values\n","data.head(5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CPjR8_ixT7eE","colab_type":"code","colab":{}},"source":["# Split into training and testing data (72/25 by default)\n","X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state=0)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nW4EUgJwT7eK","colab_type":"text"},"source":["### 1. Logistic regression model"]},{"cell_type":"code","metadata":{"id":"tdgpQ-FpT7eM","colab_type":"code","colab":{}},"source":["# Run Logistic regression\n","logreg = sklearn.linear_model.LogisticRegression().fit(X_train, y_train)\n","\n","# Print the results\n","print(\"Logistic Regression: Training accuracy: {:.3f}\".format(logreg.score(X_train, y_train)))\n","print(\"Logistic Regression: Testing accuracy: {:.3f}\".format(logreg.score(X_test, y_test)))\n","\n","print(\"intercept\"+str(logreg.intercept_))\n","print(\"coefficients:\"+str(logreg.coef_[0]))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BmPRTLlhT7eP","colab_type":"text"},"source":["### 2. Decision tree model"]},{"cell_type":"code","metadata":{"id":"uzn50yghT7eQ","colab_type":"code","colab":{}},"source":["# Run decision tree\n","tree = sklearn.tree.DecisionTreeClassifier(random_state=0).fit(X_train, y_train)\n","print(\"Decision Tree: Training accuracy: {:.3f}\".format(tree.score(X_train, y_train)))\n","print(\"Decision Tree: Testing accuracy: {:.3f}\".format(tree.score(X_test, y_test)))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"roIZWtfFT7eT","colab_type":"text"},"source":["#### 2.1 Explore feature importance and tree"]},{"cell_type":"code","metadata":{"id":"f7zGWr5xT7eU","colab_type":"code","colab":{}},"source":["print(selected_features)\n","print(tree.feature_importances_)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zz7DBcXOT7eY","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","plt.figure(figsize=(12,12))\n","sklearn.tree.plot_tree(tree, feature_names=selected_features, fontsize=10, max_depth=2)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kLFdLqZmT7ee","colab_type":"text"},"source":["#### 2.2 Performing prediction from the trained (fitted) model"]},{"cell_type":"code","metadata":{"id":"XB6wIOrxT7ee","colab_type":"code","colab":{}},"source":["#Note: input features = ['Pclass','Age', 'SibSp', 'Parch', 'Fare','binary_gender']\n","jack = [3., 19., 0., 0., 5.0, 1.0]\n","rose = [1., 17., 1., 2., 100.0, 0.0]\n","\n","print([jack,rose])\n","\n","# Predict surviving chances\n","survivor_predictions = tree.predict([jack, rose])\n","print(\"Jack Survival Rate:\", survivor_predictions[0])\n","print(\"Rose Survival Rate:\", survivor_predictions[1])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eL46LUDZT7eh","colab_type":"text"},"source":["### 3. Evaluation - calculate precision and recall"]},{"cell_type":"markdown","metadata":{"id":"vvQaIKw1T7ei","colab_type":"text"},"source":["Calculate precision and recall for the model recently fitted (either logistic regression or decision tree)"]},{"cell_type":"code","metadata":{"id":"BMWABCrCT7ej","colab_type":"code","colab":{}},"source":["# calculate precision and recall\n","\n","y_predict = logreg.predict(X_test) #use this for logistic regression \n","# y_predict = tree.predict(X_test) #use this for decision tree\n","\n","print(\"Precision score: {:.3f}\".format(sklearn.metrics.precision_score(y_test, y_predict)))\n","print(\"Recall score: {:.3f}\".format(sklearn.metrics.recall_score(y_test, y_predict)))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MhAH8Dq9T7em","colab_type":"text"},"source":["Here are the codes to plot precision-recall curve (see https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html#sphx-glr-auto-examples-model-selection-plot-precision-recall-py)\n","\n","Here I have put both the logistic regression or decision tree. However, the precision-recall curve is generally used for the threshold analysis of logistic regression."]},{"cell_type":"code","metadata":{"id":"PlP24xy9T7eo","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","\n","y_prob = logreg.decision_function(X_test) #use this for logistic regression\n","# y_prob = tree.predict_proba(X_test)[:,1]  #use this for decision tree\n","\n","precision, recall, thresholds = sklearn.metrics.precision_recall_curve(y_test, y_prob)\n","\n","plt.figure()\n","plt.step(recall, precision)\n","average_precision = sklearn.metrics.average_precision_score(y_test, y_prob)\n","\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.ylim([0.0, 1.05])\n","plt.xlim([0.0, 1.0])\n","plt.title('Average precision score: AP={0:0.2f}'.format(average_precision))"],"execution_count":0,"outputs":[]}]}