{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "S7_Demo2_Titanic.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acedesci/scanalytics/blob/master/EN/S07_Intro_ML/S7_Notebook_Example_Titanic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYWkiajyT7dy"
      },
      "source": [
        "# Session 7: Introduction to ML - Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4W6ZNmfT7dz"
      },
      "source": [
        "## Example/Demo 2: Classification on Toy Dataset (Titanic)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtkcV00mT7d1"
      },
      "source": [
        "Classification using the Dataset from Kaggle (https://www.kaggle.com/c/titanic/data). This notebook is used to produce the results of the Titanic example on the slides and it is provided as a reference. For the step-by-step detailed processes, please refer to the pipeline in the \"SimpleDemo_Telco\" file. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLD9AVYPT7d3"
      },
      "source": [
        "import sklearn\n",
        "from sklearn import *\n",
        "sklearn.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtELrpbiThlc"
      },
      "source": [
        "### Block 1: Data input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMjSEQBkT7d9"
      },
      "source": [
        "import pandas #we also need pandas package here to load the csv data\n",
        "\n",
        "# Load dataset\n",
        "url = 'https://raw.githubusercontent.com/acedesci/scanalytics/master/EN/S07_Intro_ML/data/titanic_train.csv'\n",
        "data = titanic_data = pandas.read_csv(url)\n",
        "data.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Gbr6p2ITmSl"
      },
      "source": [
        "### Block 2: Feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_VpPqSjT7eB"
      },
      "source": [
        "le_gender = sklearn.preprocessing.LabelEncoder()\n",
        "data['binary_gender'] = le_gender.fit_transform(titanic_data['Sex'].values)\n",
        "selected_features = ['Pclass','Age', 'SibSp', 'Parch', 'Fare','binary_gender']\n",
        "X = data[selected_features].fillna(0).values\n",
        "y = data['Survived'].values\n",
        "data.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPjR8_ixT7eE"
      },
      "source": [
        "# Split into training and testing data (72/25 by default)\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJpg42pWTpnf"
      },
      "source": [
        "### Block 3: ML models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW4EUgJwT7eK"
      },
      "source": [
        "1) Logistic regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdgpQ-FpT7eM"
      },
      "source": [
        "# Run Logistic regression\n",
        "logreg = sklearn.linear_model.LogisticRegression().fit(X_train, y_train)\n",
        "\n",
        "# Print the results\n",
        "print(\"Logistic Regression: Training accuracy: {:.3f}\".format(logreg.score(X_train, y_train)))\n",
        "print(\"Logistic Regression: Testing accuracy: {:.3f}\".format(logreg.score(X_test, y_test)))\n",
        "\n",
        "print(\"intercept\"+str(logreg.intercept_))\n",
        "print(\"coefficients:\"+str(logreg.coef_[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmPRTLlhT7eP"
      },
      "source": [
        "2) Decision tree model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzn50yghT7eQ"
      },
      "source": [
        "# Run decision tree\n",
        "tree = sklearn.tree.DecisionTreeClassifier(random_state=0).fit(X_train, y_train)\n",
        "print(\"Decision Tree: Training accuracy: {:.3f}\".format(tree.score(X_train, y_train)))\n",
        "print(\"Decision Tree: Testing accuracy: {:.3f}\".format(tree.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roIZWtfFT7eT"
      },
      "source": [
        "Explore feature importance and tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7zGWr5xT7eU"
      },
      "source": [
        "print(selected_features)\n",
        "print(tree.feature_importances_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz7DBcXOT7eY"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12,12))\n",
        "sklearn.tree.plot_tree(tree, feature_names=selected_features, fontsize=10, max_depth=2)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLFdLqZmT7ee"
      },
      "source": [
        "Performing prediction from the trained (fitted) model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB6wIOrxT7ee"
      },
      "source": [
        "#Note: input features = ['Pclass','Age', 'SibSp', 'Parch', 'Fare','binary_gender']\n",
        "jack = [3., 19., 0., 0., 5.0, 1.0]\n",
        "rose = [1., 17., 1., 2., 100.0, 0.0]\n",
        "\n",
        "print([jack,rose])\n",
        "\n",
        "# Predict surviving chances\n",
        "survivor_predictions = tree.predict([jack, rose])\n",
        "print(\"Jack Survival Rate:\", survivor_predictions[0])\n",
        "print(\"Rose Survival Rate:\", survivor_predictions[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eL46LUDZT7eh"
      },
      "source": [
        "### Block 4: Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvQaIKw1T7ei"
      },
      "source": [
        "Calculate precision and recall for the model recently fitted (either logistic regression or decision tree)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMWABCrCT7ej"
      },
      "source": [
        "# calculate precision and recall\n",
        "\n",
        "y_predict = logreg.predict(X_test) #use this for logistic regression \n",
        "# y_predict = tree.predict(X_test) #use this for decision tree\n",
        "\n",
        "print(\"Precision score: {:.3f}\".format(sklearn.metrics.precision_score(y_test, y_predict)))\n",
        "print(\"Recall score: {:.3f}\".format(sklearn.metrics.recall_score(y_test, y_predict)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhAH8Dq9T7em"
      },
      "source": [
        "Here are the codes to plot precision-recall curve (see https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html#sphx-glr-auto-examples-model-selection-plot-precision-recall-py)\n",
        "\n",
        "Here I have put both the logistic regression or decision tree. However, the precision-recall curve is generally used for the threshold analysis of logistic regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlP24xy9T7eo"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_prob = logreg.decision_function(X_test) #use this for logistic regression\n",
        "# y_prob = tree.predict_proba(X_test)[:,1]  #use this for decision tree\n",
        "\n",
        "precision, recall, thresholds = sklearn.metrics.precision_recall_curve(y_test, y_prob)\n",
        "\n",
        "plt.figure()\n",
        "plt.step(recall, precision)\n",
        "average_precision = sklearn.metrics.average_precision_score(y_test, y_prob)\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.title('Average precision score: AP={0:0.2f}'.format(average_precision))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}