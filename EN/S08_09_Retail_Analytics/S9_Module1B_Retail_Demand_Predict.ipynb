{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S9_Module1B_Retail_Demand_Predict.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acedesci/scanalytics/blob/master/EN/S08_09_Retail_Analytics/S9_Module1B_Retail_Demand_Predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ERJ1nA4bXHZ"
      },
      "source": [
        "# Session 8: Retail analytics - Prediction from trained models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "789YRSDLbjPQ"
      },
      "source": [
        "## Module 1B: Predicting demands from trained models for decision models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iy3AoJtPXoV"
      },
      "source": [
        "In Module 1A in session 8, we designed our model on a predetermined subset of regressor variables and trained it by UPC. Now in this notebook, we will prepare our inputs for the optimization model by predicting the demands based on different price points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2Sn0n-ZUc_E"
      },
      "source": [
        "import pandas\n",
        "import sklearn\n",
        "from sklearn import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cS5YfcZHddR"
      },
      "source": [
        "# 1. Data input\n",
        "\n",
        "We have prepared the input files which contain the features to be predicted. The first file shows a small dataset whereas the second file consists of a large dataset, i.e.,\n",
        "\n",
        "1.   **'InputFeatures_Prob1.csv'**. This is a small scale problem. The output of this will be used in the optimization model which you will see in Modules 2A (explicit model) and 2B (compact model).\n",
        "2.   **'InputFeatures_Prob2.csv'**. This is a large-scale problem. This one contains a much higher number of variables and constraints to reflect real-life setting. We will use the output of this in the Module 2B.\n",
        "\n",
        "In order to read the input, we provide two options here. Please run only either option 1 or option 2 (***not both***).\n",
        "\n",
        "**Option 1: download from the URLs**. You can you can get it directly from the URLs as usual using the codes below to download 'InputFeatures_Prob1.csv' and save it in DataFrame\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxK_p7tEka4y"
      },
      "source": [
        "# small example\n",
        "url = 'https://raw.githubusercontent.com/acedesci/scanalytics/master/EN/S08_09_Retail_Analytics/InputFeatures_Prob1.csv'\n",
        "# large example, please outcomment if you want to try\n",
        "# url = 'https://raw.githubusercontent.com/acedesci/scanalytics/master/EN/S08_09_Retail_Analytics/InputFeatures_Prob2.csv'\n",
        "\n",
        "predDemand = pandas.read_csv(url)\n",
        "\n",
        "# Dataset is now stored in a Pandas Dataframe predDemand\n",
        "predDemand"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5dxz97-k7iz"
      },
      "source": [
        "**Option 2: Read the file directly from your drive.** You can upload the file from you PC. In this option, you must already download the file *'InputFeatures_Prob1.csv'* or 'InputFeatures_Prob2.csv' from Zonecours and save to your PC. Then you can upload it using the codes in the block below. After running the cell, click on \"Choose Files\" to upload it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAvj7Z31lHOa"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "import io\n",
        "import pandas\n",
        "predDemand = pandas.read_csv(io.BytesIO(uploaded['InputFeatures_Prob1.csv']))\n",
        "\n",
        "# Dataset is now stored in a Pandas Dataframe predDemand\n",
        "predDemand"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO-xut7aO8kg"
      },
      "source": [
        "# 2. Model retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdW-CiGPO8kh"
      },
      "source": [
        "Next, we retrieve the best model that we previously trained and saved from the current working directory (cmd) based on one of the two two options below.\n",
        "\n",
        "**Option 1 Local PC (Jupyter)**: if you model is saved on PC, you need to give the path to the saved models. Here we assume that it is located in the same folder as the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4D001GGUMTZ"
      },
      "source": [
        "cwd = './'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GO4FfNAhUL8g"
      },
      "source": [
        "**Option 2 Google Drive (Colab)**: if you model is saved on Google Drive, you can access the folder by mounting it and authorizing access."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSRXAt-Nnx8M"
      },
      "source": [
        "# we need to remount Google Drive in order to load the data from it\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "cwd = '/content/drive/My Drive/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnEKiWSyO8km"
      },
      "source": [
        "Following the block above, we can now load the model that we previously trained and saved for each UPC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZu3qyoMn1WV"
      },
      "source": [
        "import pickle\n",
        "\n",
        "productList = predDemand['UPC'].unique()\n",
        "\n",
        "regr = {}\n",
        "for upc in productList:\n",
        "    filename = cwd+str(upc)+'_demand_model.sav'\n",
        "    # load the model to disk\n",
        "    regr[upc] = pickle.load(open(filename, 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7K3cDLOO8kq"
      },
      "source": [
        "# 3. Demand forecasting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFY7TznuO8ks"
      },
      "source": [
        "In this cell, we also create a loop **for** each UPC. Here are the descriptions of each line in the for loop\n",
        "\n",
        "*   The first line in the **for** loop loads the data on the explanatory variables (features) for each UPC.\n",
        "*   The second line retrives the UPC value so that we can call and run the model for that UPC.\n",
        "*   The third line takes the model object for the current UPC (*regr[upc]*) and predicts the demand. We also use the function *clip(0.0)* to make sure that the demand is non-negative (which is possible since the demand is a decreasing function of price and the regression function is unbounded) and function *round(1)* to round the predicted value to one digit.\n",
        "*   The fourth line put the predicted demand into the series which will be added as a new column\n",
        "\n",
        "Once the for loop terminated, we add a new column *'predictSales'* which shows the predicted demand."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iMU7G0yVeWk"
      },
      "source": [
        "feature_list = ['PRICE', 'PRICE_p2', 'FEATURE', 'DISPLAY','TPR_ONLY','RELPRICE']\n",
        "\n",
        "X = {}\n",
        "y_pred = {}\n",
        "\n",
        "# prepare blank series which will be added as a new column to the DataFrame predDemand\n",
        "predictedValueSeries = pandas.Series()\n",
        "\n",
        "for upc in productList:\n",
        "  # Line 1 of for loop: load the data on the explanatory variable\n",
        "  X[upc] = predDemand.loc[predDemand['UPC']==upc][feature_list]\n",
        "\n",
        "  # Line 2: retrieve the UPC value\n",
        "  upcIndex = predDemand.loc[predDemand['UPC']==upc].index\n",
        "\n",
        "  # Line 3: predice the demands and make sure the demand is non-negative\n",
        "  y_pred[upc] = regr[upc].predict(X[upc]).clip(0.0).round(1)\n",
        "\n",
        "  # Line 4: add the predicted demand to the series\n",
        "  predictedValueSeries = predictedValueSeries._append(pandas.Series(y_pred[upc], index = upcIndex))\n",
        "\n",
        "predDemand['predictSales'] = predictedValueSeries\n",
        "print(predDemand.to_string())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vypThqGJQd_K"
      },
      "source": [
        "Now we save the predicted sales into csv file to be used in the optimization model later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QmdVdfaX_jK"
      },
      "source": [
        "# Please save it as 'predictedSales_Prob1.csv' if 'InputFeatures_Prob1.csv' is used\n",
        "# Otherwise, please save it as 'predictedSales_Prob2.csv' if 'InputFeatures_Prob2.csv' is used\n",
        "predDemand.to_csv(cwd +'predictedSales_Prob1.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}