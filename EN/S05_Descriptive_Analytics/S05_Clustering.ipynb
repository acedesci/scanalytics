{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "S06_LectureEx_Clustering_Models.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acedesci/scanalytics/blob/master/EN/S05_Descriptive_Analytics/S05_Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpcq0W5adVgo"
      },
      "source": [
        "# S5 - Descriptive Analytics - Clustering Models\n",
        "Programming topics covered in this section:\n",
        "* Data transformation for descriptive analytics\n",
        "* Clustering and segmentation models\n",
        "  *   K-Means clustering and optimization\n",
        "  *   Hierarchical clustering\n",
        "\n",
        "\n",
        "\n",
        "Examples include:\n",
        "* Transportation shipment clustering analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWUOy93mdlkW"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o-4MMzmdVg0"
      },
      "source": [
        "## 1. Importing data and creating a report\n",
        "In this exercise, we make use of supply chain health commodity shipment and pricing data.The data set provides the commodity pricing and associated supply chain expenses necessary to move the commodities to countries for use. The original data are provided by the US Agency for International Development and can be accessed at [this page](https://catalog.data.gov/dataset/supply-chain-shipment-pricing-data).\n",
        "\n",
        "This is a description of our adapted data in the file `SCMS_Delivery_History_Dataset.csv`.\n",
        "\n",
        "| VARIABLE NAME | DESCRIPTION |\n",
        "|:----|:----|\n",
        "|id| identification number|\n",
        "|project code|identification of the project|\n",
        "|country|country to which the items are shipped|\n",
        "|vendor|identification of the vendor of the item|\n",
        "|manufacturing site|name of the manufacturer of the item|\n",
        "|shipment mode|transportation mode (e.g., air, truck)|\n",
        "|scheduled delivery date|programmed date for delivery|\n",
        "|delivered to client date|real date of delivery|\n",
        "|delivery recorded date|registered date of delivery|\n",
        "|product group|main category of the item|\n",
        "|product subgroup|subcategory of the item (e.g., HIV test, pediatric, Adult) |\n",
        "|molecule type|description of the composition of the item (e.g., Nevirapine, HIV 1/2, Didanosine)|\n",
        "|brand| item brand (e.g, generic or any other commercial brand)|\n",
        "|dosage| specifications about the dosage of each item (e.g.,10mg/ml, 200mg)|\n",
        "|dosage form|instructions for consumption (e.g., capsule, tablet, oral solution) |\n",
        "|units per pack| number of units in each package|\n",
        "|quantity pack sold| number of packages shipped to the specified country|\n",
        "|value sold| total value in $\\$$ USD of the shipment (i.e., pack_price * quantity pack sold|\n",
        "|pack price| price in $\\$$ USD per package|\n",
        "|unit price| price in $\\$$ USD per unit|\n",
        "|weight (kilograms)| total weight in kilograms of the shipment|\n",
        "|freight cost (usd)| value in $\\$$USD paid for transportation|\n",
        "|insurance (usd)|value in $\\$$USD paid for insurance|\n",
        "\n",
        "Similar to session 5, we will import the data, transform the columns which contain dates and numerical values to their corresponding format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "8cvKdP0cdVg0"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/acedesci/scanalytics/master/EN/S05_Data_Preprocessing/Supply_Chain_Shipment_Pricing_Data.csv'\n",
        "df_SC = pd.read_csv(url)  # reading data file into a DataFrame\n",
        "\n",
        "df_SC.columns = df_SC.columns.str.replace(' ', '_')\n",
        "df_SC.columns = df_SC.columns.str.replace('(', '')\n",
        "df_SC.columns = df_SC.columns.str.replace(')', '')\n",
        "df_SC.columns = df_SC.columns.str.replace('#', '')\n",
        "df_SC.columns = df_SC.columns.str.replace('/', '')\n",
        "\n",
        "# transform date and numerical data\n",
        "df_SC['pq_first_sent_to_client_date'] = pd.to_datetime(df_SC['pq_first_sent_to_client_date'], errors='coerce')\n",
        "df_SC['scheduled_delivery_date'] = pd.to_datetime(df_SC['scheduled_delivery_date'], errors='coerce')\n",
        "df_SC['delivered_to_client_date'] = pd.to_datetime(df_SC['delivered_to_client_date'], errors='coerce')\n",
        "df_SC['weight_kilograms'] = pd.to_numeric(df_SC['weight_kilograms'], errors='coerce')\n",
        "df_SC['freight_cost_usd'] = pd.to_numeric(df_SC['freight_cost_usd'], errors='coerce')\n",
        "\n",
        "df_SC\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdNM0u4RK7AB"
      },
      "source": [
        "For this analysis, we will also choose only data after 2010 and non-missing ones for the analysis. The only data will will use are the columns ` ['country', 'line_item_value','weight_kilograms','freight_cost_usd']`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w73ftrI-_yd"
      },
      "source": [
        "df_SC.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyi30djgK7NA"
      },
      "source": [
        "# choose only non-missing data and data after 2010\n",
        "df_SC = df_SC[(df_SC['freight_cost_usd'].notna()) & (df_SC['weight_kilograms'].notna()) & (df_SC['delivered_to_client_date'] >= '2010-01-01')]\n",
        "\n",
        "selected_columns = ['country', 'line_item_value','weight_kilograms','freight_cost_usd']\n",
        "print(df_SC[selected_columns].isna().sum())\n",
        "df_SC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efTwqVwELSgV"
      },
      "source": [
        "Since the clustering analysis will be perform at the country level, we will use the function groupby to prepare the input. The function `df.groupby(...).agg(...)` allows us to aggregate each column differently based on what specified in the dictionary. You can review more details here: [link1](https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.core.groupby.DataFrameGroupBy.agg.html) and here [link2](https://pbpython.com/groupby-agg.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8slfTYMLSsP"
      },
      "source": [
        "df_SC_selected = df_SC[selected_columns].groupby(['country']).agg({'line_item_value':'sum','weight_kilograms':'mean','freight_cost_usd':'mean'})\n",
        "df_SC_selected"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5fUv07LM4lI"
      },
      "source": [
        "Since clustering algorithms are typically highly influenced by scale (e.g. not scale-invariant), one common practice is to normalize the data before use. We opt for `z-score` normalization. We also keep the list of column names containing normal values and normalized values to make it easier when making a reference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYcFyIYOM47l"
      },
      "source": [
        "for col in df_SC_selected.columns:\n",
        "    df_SC_selected['z_'+col] = (df_SC_selected[col] - df_SC_selected[col].mean())/df_SC_selected[col].std()\n",
        "\n",
        "normal_columns = list(df_SC_selected.columns[:3])\n",
        "z_columns = list(df_SC_selected.columns[3:])\n",
        "\n",
        "df_SC_selected"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7tktyG4dNbz"
      },
      "source": [
        "Now we can explore the data using the pairwise plot in seaborn.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziCgge_P5HmC"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.pairplot(data=df_SC_selected[normal_columns], palette = 'deep')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6TH8BJPQLoj"
      },
      "source": [
        "## Model 1: K-Means clustering\n",
        "\n",
        "We first apply K-Means clutering algorithm using the commonly used package `scikit-learn`. The function `sklearn.cluster.KMeans(...)` return an object which gives multiple outputs (link provided below). The main output is `.labels_` (note that this is a specific attribute name provided by the method) which returns the list containing the cluster label of all the data points. In order to learn/determine the labels from the data, we also need to call `.fit(X)` to pass the input variables `X` (our z-score normalized variables) to the method.\n",
        "\n",
        "[link to description](https://scikit-learn.org/stable/modules/clustering.html#k-means) and [link to KMeans function](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Alu2ANCL3Ixp"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
        "\n",
        "# K-Means clustering\n",
        "\n",
        "# first select only the variables which we want to use for clustering\n",
        "X = df_SC_selected[z_columns]\n",
        "\n",
        "# create a K-Means object using the number of clusters = 3 and fit to the data\n",
        "# note that K-Means algorithm is initiated using a randomized process,\n",
        "# thus we indicate `random_state=0` to fix the random seed to make sure the same result is returned every time we run\n",
        "kmeans_object = sklearn.cluster.KMeans(n_clusters=3, random_state=0)\n",
        "kmeans_object.fit(X) # you can either put `.fit(...) after the object to in a separate line like this`\n",
        "\n",
        "# now we obtain the list of cluster labels and add it to the original DataFrame\n",
        "# note that the label ID might change in a different run but the cluster remains the same if the seed is the same\n",
        "# (e.g., data point 1 has label 0 in the first time we run but then label 2 in another run but still belongs to the same data cluster)\n",
        "df_SC_selected['K3_cluster'] = kmeans_object.labels_\n",
        "df_SC_selected.tail()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuZlzVyrAFY-"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.pairplot(data=df_SC_selected[normal_columns+[\"K3_cluster\"]], hue='K3_cluster', palette = 'deep')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1GprXA_Yt5k"
      },
      "source": [
        "\n",
        "In order to choose the optimal number of clusters (in case it is not predefined), we can compare the results based on a different number of\n",
        "\n",
        "\n",
        "*   **Inertia** or sum-of-square (SSE) within the cluster: This one measure the compactness of each cluster. It is the objective function that the standard K-Means algorithm optimizes (see [link](https://scikit-learn.org/stable/modules/clustering.html)). This can be obtained through the attribute `.inertia_` from the K-Means object.\n",
        "*   **Silhouette** value: This one represents how well the clusters are separated from each others (ee [link](https://scikit-learn.org/stable/modules/clustering.html#silhouette-coefficient)). This can be done through the method `sklearn.metrics.silhouette_score(X, cluster_labels)`.\n",
        "\n",
        "In practice, a lower number of clusters is typically preferred so we choose the number of clusters where significant improvements are observed in both measures among reasonable choices of $k$.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmUaUZ0UYuTC"
      },
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# list the acceptable range of the number of clusters to explore\n",
        "kmeans_range = list(range(2,11))\n",
        "\n",
        "# prepare empty lists to store the inertia and silhouette values\n",
        "inertia_list = []\n",
        "silhouette_list = []\n",
        "\n",
        "for k in kmeans_range:\n",
        "  # fit the clustering algorithm\n",
        "  kmeans_object = sklearn.cluster.KMeans(n_clusters=k, random_state=0).fit(X)\n",
        "\n",
        "  # obtain the inertia and add the result to the list\n",
        "  inertia_list.append(kmeans_object.inertia_)\n",
        "\n",
        "  # calculate the silhouette score by providing data X and labels, then add the result to the list\n",
        "  silhouette_val = sklearn.metrics.silhouette_score(X, kmeans_object.labels_)\n",
        "  silhouette_list.append(silhouette_val)\n",
        "\n",
        "\n",
        "# calculate the marginal difference of silhouette for each step of k\n",
        "diff_silhouette = [silhouette_list[i] - silhouette_list[max(0,i-1)] for i in range(len(kmeans_range))]\n",
        "# calculate the marginal difference of inertia for each step of k\n",
        "diff_inertia = [inertia_list[i] - inertia_list[max(0,i-1)] for i in range(len(kmeans_range))]\n",
        "\n",
        "# Plot the results using seaborn using a grid of 4 subplots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 5))\n",
        "fig.suptitle('K-means clustering')\n",
        "\n",
        "sns.lineplot(ax=axes[0,0], x=kmeans_range, y=silhouette_list).set_title('Average silhouette value')\n",
        "sns.lineplot(ax=axes[0,1], x=kmeans_range, y=inertia_list).set_title('Average SSE value')\n",
        "sns.barplot(ax=axes[1,0], x=kmeans_range, y=diff_silhouette, alpha=0.5)\n",
        "sns.barplot(ax=axes[1,1], x=kmeans_range, y=diff_inertia, alpha=0.5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5LM5VsNf8hK"
      },
      "source": [
        "## Model 2: Hierarchical clustering\n",
        "\n",
        "In some cases, we must create a hierarchy of the clusters/groups rather than just a single level cluster to allow different levels of aggregation and disaggregation (e.g., product/customer hierarchy). One of the commonly used methods is Agglomerative Clustering which can be used to ensure this hierarchical consistency of the clusters. More details can be found on [link to description](https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering) and [link to the function](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html)\n",
        "\n",
        "Here we will demonstrate the concept by showing the results based on the number of clusters $k=2, 3, 4$. The default version of this method optimizes the within-cluster sum of squares which is the same objective as in the standard K-Means (but other objectives are available as described in the link)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "higKBcfeWQXb"
      },
      "source": [
        "# Hierarchical clustering\n",
        "hcluster2 = sklearn.cluster.AgglomerativeClustering(n_clusters=2).fit(X)\n",
        "df_SC_selected['A2_cluster'] = hcluster2.labels_\n",
        "\n",
        "# print out the number of countries under each cluster\n",
        "print(df_SC_selected['A2_cluster'].value_counts())\n",
        "\n",
        "hcluster3 = sklearn.cluster.AgglomerativeClustering(n_clusters=3).fit(X)\n",
        "df_SC_selected['A3_cluster'] = hcluster3.labels_\n",
        "\n",
        "# print out the number of countries under each cluster\n",
        "print(df_SC_selected['A3_cluster'].value_counts())\n",
        "\n",
        "hcluster4 = sklearn.cluster.AgglomerativeClustering(n_clusters=4).fit(X)\n",
        "df_SC_selected['A4_cluster'] = hcluster4.labels_\n",
        "\n",
        "# print out the number of countries under each cluster\n",
        "print(df_SC_selected['A4_cluster'].value_counts())\n",
        "\n",
        "df_SC_selected.tail(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nj40Ml8UrPNF"
      },
      "source": [
        "Now we plot the clusters using seaborn scatter plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_9pGRrGPduH"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5),sharey=True)\n",
        "fig.suptitle('Hierarchical clustering')\n",
        "\n",
        "# 2 clusters\n",
        "sns.scatterplot(data = df_SC_selected, ax=axes[0], x=normal_columns[1], y=normal_columns[2], \\\n",
        "                hue='A2_cluster', style='A2_cluster', palette='dark', s=50)\n",
        "axes[0].set_title('A2_cluster')\n",
        "\n",
        "# 3 clusters\n",
        "sns.scatterplot(data = df_SC_selected, ax=axes[1], x=normal_columns[1], y=normal_columns[2], \\\n",
        "                hue='A3_cluster', style='A3_cluster', palette='dark', s=50)\n",
        "axes[1].set_title('A3_cluster')\n",
        "\n",
        "# 4 clusters\n",
        "sns.scatterplot(data = df_SC_selected, ax=axes[2], x=normal_columns[1], y=normal_columns[2], \\\n",
        "                hue='A4_cluster', style='A4_cluster', palette='dark', s=50)\n",
        "axes[2].set_title('A4_cluster')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}