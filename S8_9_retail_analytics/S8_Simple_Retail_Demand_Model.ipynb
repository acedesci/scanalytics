{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S8_Simple_Retail_Demand_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acedesci/scanalytics/blob/master/S8_9_retail_analytics/S8_Simple_Retail_Demand_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78yhclufYaJB"
      },
      "source": [
        "# Session 8: Retail analytics - Predictive Model Traning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCMdPiSdYa9n"
      },
      "source": [
        "## Demo: Simplified retail prediction pipeline for a single item"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cS5YfcZHddR"
      },
      "source": [
        "### NOTE:### \n",
        "This is a simplified version of the predictive model shown in the Module 1  for session 8. In this version, we run only the model for one item. Almost all of the parts of the codes folllow the same logic and process as the Module 1A [[Colab link for 1A]](https://colab.research.google.com/github/acedesci/scanalytics/blob/master/S8_9_retail_analytics/S8_Module1A_Retail_Demand_Model.ipynb) but it is simplified to one product (UPC). Once you are familiar with this one, it will be easy to understand the demo 1A which consists of multiple items.\n",
        "\n",
        "In order to continue for S9 for the optimization model, we still need to run the Module 1A. Thus, please also proceed and run the Module 1A and save the fitted models to your Google Drive or local folder.\n",
        "\n",
        "We begin by loading the required packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2Sn0n-ZUc_E"
      },
      "source": [
        "import pandas\n",
        "import numpy\n",
        "import sklearn\n",
        "from sklearn import *\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHEG7lxh_2ft"
      },
      "source": [
        "# Block 1: Data input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLFF9nhH_2fu"
      },
      "source": [
        "In addition to the original data, we add a new variable, which is the squared price ('PRICE_p2')."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nllChVoSUtNy"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/acedesci/scanalytics/master/S8_9_retail_analytics/salesCereals.csv'\n",
        "\n",
        "salesCereals = pandas.read_csv(url)\n",
        "salesCereals['PRICE_p2'] = salesCereals['PRICE']**2\n",
        "salesCereals.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx07EKzc_2f-"
      },
      "source": [
        "'UPC' stands for Universal Product Code, which can be understood as one SKU in this case and in our SCM terms in general. The code below helps us identify the SKUs by which we want to forecast and their corresponding data size (number of data instances). We can see that the number of instances for each UPC is similar and that there is no UPC with only a few data points. This is important because training a model on a small dataset may limit its generalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iMU7G0yVeWk"
      },
      "source": [
        "print(salesCereals.groupby('UPC').count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ_aCZWP_2gD"
      },
      "source": [
        "# Block 2: Feature engineering & preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F79zzD1_2gE"
      },
      "source": [
        "We then organize the data by 'UPC.' The model presented here only runs on a predetermined subset of variables in the data. You can add or remove these explanatory variables based on your judgemental call. \n",
        "\n",
        "Here we select only **one** upc to run the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QmdVdfaX_jK"
      },
      "source": [
        "feature_list = ['PRICE', 'PRICE_p2', 'FEATURE', 'DISPLAY','TPR_ONLY','RELPRICE']\n",
        "\n",
        "productList = salesCereals['UPC'].unique()\n",
        "upc = 1600027528\n",
        "\n",
        "X = salesCereals.loc[salesCereals['UPC']==upc][feature_list]\n",
        "y = salesCereals.loc[salesCereals['UPC']==upc]['UNITS']\n",
        "  # Split into training and testing data\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJad8yq0_2gS"
      },
      "source": [
        "# Block 3: Model & algorithm (training & testing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4D_uOPk_2gX"
      },
      "source": [
        "In the next two cells, we train and test two different types of models, namely Linear Regression and Tree Regression. The first line in each loop is to train the model and the second line is for testing the model's performance on unseen data. The next three lines compute the performance metrics we would like to measure. Then we compute metrics to show the performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THvq_pEyerzL"
      },
      "source": [
        "#Linear model\n",
        "\n",
        "# Fit the model\n",
        "regr = sklearn.linear_model.LinearRegression().fit(X_train,y_train)\n",
        "\n",
        "# Measure the RSME on the training set\n",
        "trainRMSE = numpy.sqrt(sklearn.metrics.mean_squared_error(y_train, regr.predict(X_train)))\n",
        "\n",
        "# Prediction on the test set\n",
        "y_pred = regr.predict(X_test)\n",
        "\n",
        "# Measure the prediction performances on the test set\n",
        "testMAE = sklearn.metrics.mean_absolute_error(y_test, y_pred)\n",
        "testMAPE = numpy.mean(numpy.abs((y_test - y_pred) / y_test))\n",
        "testRMSE = numpy.sqrt(sklearn.metrics.mean_squared_error(y_test, y_pred))\n",
        "    \n",
        "print('Linear regression Summary - UPC:'+str(upc))\n",
        "print('Training RMSE:' + str(round(trainRMSE,2)))\n",
        "print('Testing RMSE:' + str(round(testMAE,2)))\n",
        "print('Testing MAE:' + str(round(testMAPE,2)))\n",
        "print('Testing MAPE:' + str(round(testRMSE,2)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtxnVPUfJi6x"
      },
      "source": [
        "In order to see the impact of the price on the demand, we use a simple plot function below from mathplotlib to see how the demand would change when the price changes.\n",
        "\n",
        "For more details of the plot function, please see: https://matplotlib.org/api/_as_gen/matplotlib.pyplot.plot.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXtyo4WkHzvQ"
      },
      "source": [
        "prices = [2.0, 2.25, 2.5, 2.75, 3.0, 3.25, 3.5, 3.75, 4.0]\n",
        "input_x = []\n",
        "\n",
        "# generate inputs for the plot using simple feature values and varying price points\n",
        "for p in prices:\n",
        "  input_x.append([p, p**2, 0,0,0, 1.0])\n",
        "  \n",
        "# obtain the predicted demands\n",
        "predict_y = regr.predict(input_x)\n",
        "plt.plot(prices, predict_y, marker='o')\n",
        "plt.xlabel('Price')\n",
        "plt.ylabel('Demand') \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7t24jaI_2gm"
      },
      "source": [
        "Likewise, we obtain the tree regression results by simply changing the function name. Here you can try the regression tree and random forest (second model) if you outcomment it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0wTwOc5eZxD"
      },
      "source": [
        "#Tree models\n",
        "# regr = sklearn.tree.DecisionTreeRegressor(random_state = 0).fit(X_train,y_train) # standard regression tree\n",
        "regr = sklearn.ensemble.RandomForestRegressor(random_state = 0).fit(X_train,y_train) # random forest tree\n",
        "\n",
        "# Measure the RSME on the training set\n",
        "trainRMSE = numpy.sqrt(sklearn.metrics.mean_squared_error(y_train, regr.predict(X_train)))\n",
        "\n",
        "# Prediction on the test set\n",
        "y_pred = regr.predict(X_test)\n",
        "\n",
        "# Measure the prediction performances on the test set\n",
        "testMAE = sklearn.metrics.mean_absolute_error(y_test, y_pred)\n",
        "testMAPE = numpy.mean(numpy.abs((y_test - y_pred) / y_test))\n",
        "testRMSE = numpy.sqrt(sklearn.metrics.mean_squared_error(y_test, y_pred))\n",
        "    \n",
        "print('Tree regression Summary - UPC:'+str(upc))\n",
        "print('Training RMSE:' + str(round(trainRMSE,2)))\n",
        "print('Testing RMSE:' + str(round(testMAE,2)))\n",
        "print('Testing MAE:' + str(round(testMAPE,2)))\n",
        "print('Testing MAPE:' + str(round(testRMSE,2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCn-K6OOKex6"
      },
      "source": [
        "# plot to see how the results look like when changing prices\n",
        "prices = [2.0, 2.25, 2.5, 2.75, 3.0, 3.25, 3.5, 3.75, 4.0]\n",
        "input_x = []\n",
        "\n",
        "# generate inputs for the plot using simple feature values and varying price points\n",
        "for p in prices:\n",
        "  input_x.append([p, p**2, 0,0,0, 1.0])\n",
        "  \n",
        "input_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejbHASguwDhR"
      },
      "source": [
        "# obtain the predicted demands\r\n",
        "predict_y = regr.predict(input_x)\r\n",
        "plt.plot(prices, predict_y, marker='o')\r\n",
        "plt.xlabel('Price')\r\n",
        "plt.ylabel('Demand') \r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUIT5AIn_2gy"
      },
      "source": [
        "# Block 4: Model selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1CjAbsg_2gz"
      },
      "source": [
        "By comparing the average result, we can see that the linear regression model slightly outperformed the decision tree regression and did not overfit the data. In addtion, the predicted function has a better representation since the changes are monotonic (from the plots). Therefore, we proceed with the linear regression model for the whole dataset by replacing 'X_train' with 'X'. Given that the model has 'seen' the whole dataset, its forecast errors normally decrease. Therefore, we will save the trained model and use it for the new data which will be used in the optimization models in the next session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYJ4WZyW2O6I"
      },
      "source": [
        "# Selected model\n",
        "\n",
        "# Fit the model on the entire dataset\n",
        "regr = sklearn.linear_model.LinearRegression().fit(X,y)\n",
        "\n",
        "# Prediction on the test set\n",
        "y_pred = regr.predict(X)\n",
        "\n",
        "# Measure the prediction performances on the entire dataset\n",
        "overallMAE = sklearn.metrics.mean_absolute_error(y, y_pred)\n",
        "overallMAPE = numpy.mean(numpy.abs((y - y_pred) / y))\n",
        "overallRMSE = numpy.sqrt(sklearn.metrics.mean_squared_error(y, y_pred))\n",
        "    \n",
        "print('Regression Summary - UPC:'+str(upc))\n",
        "print('Overall RMSE:' + str(round(overallMAE,2)))\n",
        "print('Overall MAE:' + str(round(overallMAPE,2)))\n",
        "print('Overall MAPE:' + str(round(overallRMSE,2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJIp30KhYuJg"
      },
      "source": [
        "## Save trained models\r\n",
        "\r\n",
        "**Option 1 Jupyter**: If you use Jupyter, you can save it to a local folder. The code below will put it in the current folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frGIJo8-YuyK"
      },
      "source": [
        "cwd = './'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l7zG_eLYvCA"
      },
      "source": [
        "**Option 2 Colab**: If you use Colab, in addition to downloading the results as we did in the previous session (not shown here), you can also save to your Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOioZELmYvgA"
      },
      "source": [
        "# we need to remount Google Drive in order to save into it\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "cwd = '/content/drive/My Drive/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNpZYZnJYvw8"
      },
      "source": [
        "Now we can save the files to the folder indicated by using the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF5XjbHAmVYG"
      },
      "source": [
        "# save the models to drive (here we save model only for one UPC). \n",
        "import pickle\n",
        "\n",
        "filename = cwd+str(upc)+'_single_upc_demand_model.sav'\n",
        "# save the model to disk\n",
        "pickle.dump(regr, open(filename, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}