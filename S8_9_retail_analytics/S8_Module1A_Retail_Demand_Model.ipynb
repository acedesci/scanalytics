{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S8_Module1A_Retail_Demand_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acedesci/scanalytics/blob/master/S8_9_retail_analytics/S8_Module1A_Retail_Demand_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cS5YfcZHddR",
        "colab_type": "text"
      },
      "source": [
        "We begin by loading the required packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2Sn0n-ZUc_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas\n",
        "import numpy\n",
        "import sklearn\n",
        "from sklearn import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2GH_grXDkFD",
        "colab_type": "text"
      },
      "source": [
        "## *Supplement - Plot functions (this is a pre-built plot function)*\n",
        "\n",
        "*They will be used later on for visualizations. There is no need to go through them. You only need to run the codes.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFbj2EDsDr3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#See https://matplotlib.org/devdocs/gallery/subplots_axes_and_figures/subplots_demo.html\n",
        "\n",
        "def plot_data_scatter(data_x, data_y, X_test, y_pred, feature_list):\n",
        "    # Plot the results\n",
        "\n",
        "    n_row_plot = int((len(feature_list)+1)/2) # 2 plots per row\n",
        "    n_col_plot = 2\n",
        "    fig, ax = plt.subplots(n_row_plot, n_col_plot, figsize=(12, 12))\n",
        "    \n",
        "    i = 0 # column index of the plot\n",
        "    j = 0 # row index of the plot\n",
        "        \n",
        "    for count in range(len(feature_list)):\n",
        "        #print(data_x[:,i])\n",
        "        ax[j, i].scatter(data_x[:,min(count,len(feature_list))], data_y, s=20, edgecolor=\"black\",\n",
        "                    c=\"darkorange\", label=\"data\")\n",
        "        ax[j, i].scatter(X_test.values[:,min(count,len(feature_list))], y_pred, s=30, marker=\"X\", \n",
        "                    c=\"royalblue\", label=\"prediction\")\n",
        "        ax[j, i].set(title=feature_list[count])\n",
        "        \n",
        "        ax[j, i].set(ylabel='UNITS')\n",
        "            \n",
        "        i = min(i+1,len(feature_list)) % n_col_plot\n",
        "        if i == 0: j += 1\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HHEG7lxh_2ft"
      },
      "source": [
        "# Block 1: Data input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NLFF9nhH_2fu"
      },
      "source": [
        "In addition to the original data, we add a new variable, which is the squared price ('PRICE_p2')."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nllChVoSUtNy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "876c7635-3bc5-4f6f-f81b-da3ef9064f0a"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/acedesci/scanalytics/master/S8_9_retail_analytics/salesCereals.csv'\n",
        "\n",
        "salesCereals = pandas.read_csv(url)\n",
        "salesCereals['PRICE_p2'] = salesCereals['PRICE']**2\n",
        "salesCereals.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>WEEK_END_DATE</th>\n",
              "      <th>STORE_NUM</th>\n",
              "      <th>UPC</th>\n",
              "      <th>UNITS</th>\n",
              "      <th>VISITS</th>\n",
              "      <th>HHS</th>\n",
              "      <th>SPEND</th>\n",
              "      <th>PRICE</th>\n",
              "      <th>BASE_PRICE</th>\n",
              "      <th>FEATURE</th>\n",
              "      <th>DISPLAY</th>\n",
              "      <th>TPR_ONLY</th>\n",
              "      <th>Desc</th>\n",
              "      <th>Category</th>\n",
              "      <th>Sub-Category</th>\n",
              "      <th>SUMPRICE</th>\n",
              "      <th>COUNTPRICE</th>\n",
              "      <th>AVGPRICE</th>\n",
              "      <th>RELPRICE</th>\n",
              "      <th>PRICE_p2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>2009-01-14</td>\n",
              "      <td>367.0</td>\n",
              "      <td>1111085319</td>\n",
              "      <td>14.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>26.32</td>\n",
              "      <td>1.88</td>\n",
              "      <td>1.88</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>PL HONEY NUT TOASTD OATS</td>\n",
              "      <td>COLD CEREAL</td>\n",
              "      <td>ALL FAMILY CEREAL</td>\n",
              "      <td>19.54</td>\n",
              "      <td>7</td>\n",
              "      <td>2.791429</td>\n",
              "      <td>0.673490</td>\n",
              "      <td>3.5344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>2009-01-14</td>\n",
              "      <td>367.0</td>\n",
              "      <td>1111085350</td>\n",
              "      <td>35.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>69.30</td>\n",
              "      <td>1.98</td>\n",
              "      <td>1.98</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>PL BT SZ FRSTD SHRD WHT</td>\n",
              "      <td>COLD CEREAL</td>\n",
              "      <td>ALL FAMILY CEREAL</td>\n",
              "      <td>19.54</td>\n",
              "      <td>7</td>\n",
              "      <td>2.791429</td>\n",
              "      <td>0.709314</td>\n",
              "      <td>3.9204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12</td>\n",
              "      <td>2009-01-14</td>\n",
              "      <td>367.0</td>\n",
              "      <td>1600027527</td>\n",
              "      <td>12.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>38.28</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>GM HONEY NUT CHEERIOS</td>\n",
              "      <td>COLD CEREAL</td>\n",
              "      <td>ALL FAMILY CEREAL</td>\n",
              "      <td>19.54</td>\n",
              "      <td>7</td>\n",
              "      <td>2.791429</td>\n",
              "      <td>1.142784</td>\n",
              "      <td>10.1761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13</td>\n",
              "      <td>2009-01-14</td>\n",
              "      <td>367.0</td>\n",
              "      <td>1600027528</td>\n",
              "      <td>31.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>142.29</td>\n",
              "      <td>4.59</td>\n",
              "      <td>4.59</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>GM CHEERIOS</td>\n",
              "      <td>COLD CEREAL</td>\n",
              "      <td>ALL FAMILY CEREAL</td>\n",
              "      <td>19.54</td>\n",
              "      <td>7</td>\n",
              "      <td>2.791429</td>\n",
              "      <td>1.644319</td>\n",
              "      <td>21.0681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14</td>\n",
              "      <td>2009-01-14</td>\n",
              "      <td>367.0</td>\n",
              "      <td>1600027564</td>\n",
              "      <td>56.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>152.32</td>\n",
              "      <td>2.72</td>\n",
              "      <td>3.07</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>GM CHEERIOS</td>\n",
              "      <td>COLD CEREAL</td>\n",
              "      <td>ALL FAMILY CEREAL</td>\n",
              "      <td>19.54</td>\n",
              "      <td>7</td>\n",
              "      <td>2.791429</td>\n",
              "      <td>0.974411</td>\n",
              "      <td>7.3984</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0 WEEK_END_DATE  STORE_NUM  ...  AVGPRICE  RELPRICE  PRICE_p2\n",
              "0           6    2009-01-14      367.0  ...  2.791429  0.673490    3.5344\n",
              "1           8    2009-01-14      367.0  ...  2.791429  0.709314    3.9204\n",
              "2          12    2009-01-14      367.0  ...  2.791429  1.142784   10.1761\n",
              "3          13    2009-01-14      367.0  ...  2.791429  1.644319   21.0681\n",
              "4          14    2009-01-14      367.0  ...  2.791429  0.974411    7.3984\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Dx07EKzc_2f-"
      },
      "source": [
        "'UPC' stands for Unique Product Code, which can be understood as one SKU in this case and in our SCM terms in general. The code below helps us identify the SKUs by which we want to forecast and their corresponding data size (number of data instances). We can see that the number of instances for each UPC is similar and that there is no UPC with only a few data points. This is important because training a model on a small dataset may limit its generalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iMU7G0yVeWk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "fd3d51ff-0928-4f57-bf84-f6c5e7f53f5e"
      },
      "source": [
        "print(salesCereals.groupby('UPC').count())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Unnamed: 0  WEEK_END_DATE  STORE_NUM  ...  AVGPRICE  RELPRICE  PRICE_p2\n",
            "UPC                                               ...                              \n",
            "1111085319         156            156        156  ...       156       156       156\n",
            "1111085350         156            156        156  ...       156       156       156\n",
            "1600027527         156            156        156  ...       156       156       156\n",
            "1600027528         156            156        156  ...       156       156       156\n",
            "1600027564         155            155        155  ...       155       155       155\n",
            "3000006340         133            133        133  ...       133       133       133\n",
            "3800031829         155            155        155  ...       155       155       155\n",
            "\n",
            "[7 rows x 20 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TQ_aCZWP_2gD"
      },
      "source": [
        "# Block 2: Feature engineering & preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0F79zzD1_2gE"
      },
      "source": [
        "We then organize the data by 'UPC.' The model presented here only runs on a predetermined subset of variables in the data. You can add or remove these explanatory variables based on your judgemental call. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QmdVdfaX_jK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "aef62624-c34d-4ce4-b4e9-1e070e217417"
      },
      "source": [
        "feature_list = ['PRICE', 'PRICE_p2', 'FEATURE', 'DISPLAY','TPR_ONLY','RELPRICE']\n",
        "\n",
        "productList = salesCereals['UPC'].unique()\n",
        "print(productList)\n",
        "\n",
        "X, X_train, X_test = {}, {}, {}\n",
        "y, y_train, y_test, y_pred = {}, {}, {}, {}\n",
        "\n",
        "for upc in productList:\n",
        "  \n",
        "  X[upc] = salesCereals.loc[salesCereals['UPC']==upc][feature_list]\n",
        "  y[upc] = salesCereals.loc[salesCereals['UPC']==upc]['UNITS']\n",
        "  # Split into training and testing data\n",
        "  X_train[upc], X_test[upc], y_train[upc], y_test[upc] = sklearn.model_selection.train_test_split(X[upc], y[upc], test_size=0.25, random_state=0)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1111085319 1111085350 1600027527 1600027528 1600027564 3000006340\n",
            " 3800031829]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NJad8yq0_2gS"
      },
      "source": [
        "# Block 3: Model & algorithm (training & testing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f4D_uOPk_2gX"
      },
      "source": [
        "In the next two cells, we train and test two different types of models, namely Linear Regression and Tree Regression. In each cell, we create a loop **for** each UPC on the product list. The first line in each loop is to train the model and the second line is for testing the model's performance on unseen data. The next three lines compute the performance metrics we would like to measure.\n",
        "\n",
        "We organize the linear regression result by 'UPC' (row) and performance metrics (columns). Then we create a dataframe and put the computed metric in the corresponding column (the last line in each loop)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THvq_pEyerzL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "6b755b81-1a53-4916-c94c-00e9a23ee8c7"
      },
      "source": [
        "#Linear model\n",
        "regr = {}\n",
        "regrSummary = pandas.DataFrame(columns=['trainRMSE', 'testRMSE','testMAE','testMAPE'], index = productList)\n",
        "\n",
        "for upc in productList:\n",
        "    regr[upc] = sklearn.linear_model.LinearRegression().fit(X_train[upc],y_train[upc])\n",
        "    trainRMSE = numpy.sqrt(sklearn.metrics.mean_squared_error(y_train[upc], regr[upc].predict(X_train[upc])))\n",
        "    y_pred[upc] = regr[upc].predict(X_test[upc])\n",
        "\n",
        "    testMAE = sklearn.metrics.mean_absolute_error(y_test[upc], y_pred[upc])\n",
        "    testMAPE = numpy.mean(numpy.abs((y_test[upc] - y_pred[upc]) / y_test[upc]))\n",
        "    testRMSE = numpy.sqrt(sklearn.metrics.mean_squared_error(y_test[upc], y_pred[upc]))\n",
        "    regrSummary.loc[upc] =  [trainRMSE, testRMSE, testMAE, testMAPE]\n",
        "\n",
        "print('Linear regression Summary')\n",
        "print(regrSummary)\n",
        "print('average training RMSE:' + str(round(regrSummary['trainRMSE'].mean(),2)))\n",
        "print('average testing RMSE:' + str(round(regrSummary['testRMSE'].mean(),2)))\n",
        "print('average testing MAE:' + str(round(regrSummary['testMAE'].mean(),2)))\n",
        "print('average testing MAPE:' + str(round(regrSummary['testMAPE'].mean(),2)))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear regression Summary\n",
            "           trainRMSE testRMSE  testMAE  testMAPE\n",
            "1111085319   7.71271    8.233  6.56893  0.838554\n",
            "1111085350    7.3059  7.69617  6.13527  0.748932\n",
            "1600027527   15.0733  23.5199  13.5468  0.547776\n",
            "1600027528   9.07337  14.0652  8.08809  0.251657\n",
            "1600027564   8.77001  6.79671  5.23954   0.27655\n",
            "3000006340   4.25569   3.8743  2.88635  0.720298\n",
            "3800031829   7.65033  8.51852  6.57475  0.379121\n",
            "average training RMSE:8.55\n",
            "average testing RMSE:10.39\n",
            "average testing MAE:7.01\n",
            "average testing MAPE:0.54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMtJCC1oJ3Gy",
        "colab_type": "text"
      },
      "source": [
        "Here we visualize the data points and the predictions using the previously defined plot function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-nYM7TvEBMl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "e658e967-0a2b-4c1c-dc2d-eb0839087e40"
      },
      "source": [
        "# Plot prediction results for a product (UPC)\n",
        "upc = productList[1]\n",
        "data_y = salesCereals.loc[salesCereals['UPC']==upc]['UNITS'].values\n",
        "data_x = salesCereals.loc[salesCereals['UPC']==upc][feature_list].values\n",
        "plot_data_scatter(data_x, data_y, X_test[upc], y_pred[upc], feature_list)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-632b9d94a498>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msalesCereals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msalesCereals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'UPC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mupc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'UNITS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msalesCereals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msalesCereals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'UPC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mupc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mupc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mupc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'plot' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtxnVPUfJi6x",
        "colab_type": "text"
      },
      "source": [
        "In order to see the impact of the price on the demand, we use a simple plot function below from mathplotlib to see how the demand would change when the price changes.\n",
        "\n",
        "For more details of the plot function, please see: https://matplotlib.org/api/_as_gen/matplotlib.pyplot.plot.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXtyo4WkHzvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "upc = productList[1]\n",
        "input_x = []\n",
        "prices = [2.0, 2.25, 2.5, 2.75, 3.0, 3.25, 3.5, 3.75, 4.0]\n",
        "\n",
        "# generate inputs for the plot using simple feature values and varying price points\n",
        "for p in prices:\n",
        "  input_x.append([p, p**2, 0,0,0, 1.0])\n",
        "  \n",
        "# obtain the predicted demands\n",
        "predict_y = regr[upc].predict(input_x)\n",
        "plt.plot(prices, predict_y, marker='o')\n",
        "plt.xlabel('Price')\n",
        "plt.ylabel('Demand') \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p7t24jaI_2gm"
      },
      "source": [
        "Likewise, we obtain the tree regression results by simply changing the function name and the result table name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0wTwOc5eZxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Tree models\n",
        "regr = {}\n",
        "regrSummary = pandas.DataFrame(columns=['trainRMSE', 'testRMSE','testMAE','testMAPE'], index = productList)\n",
        "\n",
        "for upc in productList:\n",
        "      \n",
        "    regr[upc] = sklearn.tree.DecisionTreeRegressor(random_state = 0).fit(X_train[upc],y_train[upc]) # standard regression tree\n",
        "    # regr[upc] = sklearn.ensemble.RandomForestRegressor(random_state = 0).fit(X_train[upc],y_train[upc]) # random forest tree\n",
        "    trainRMSE = numpy.sqrt(sklearn.metrics.mean_squared_error(y_train[upc], regr[upc].predict(X_train[upc])))\n",
        "    y_pred[upc] = regr[upc].predict(X_test[upc])\n",
        "\n",
        "    testMAE = sklearn.metrics.mean_absolute_error(y_test[upc], y_pred[upc])\n",
        "    testMAPE = numpy.mean(numpy.abs((y_test[upc] - y_pred[upc]) / y_test[upc]))\n",
        "    testRMSE = numpy.sqrt(sklearn.metrics.mean_squared_error(y_test[upc], y_pred[upc]))\n",
        "    regrSummary.loc[upc] =  [trainRMSE, testRMSE, testMAE, testMAPE]\n",
        "\n",
        "print('Regression Tree Summary')\n",
        "print(regrSummary)\n",
        "print('average training RMSE:' + str(round(regrSummary['trainRMSE'].mean(),2)))\n",
        "print('average testing RMSE:' + str(round(regrSummary['testRMSE'].mean(),2)))\n",
        "print('average testing MAE:' + str(round(regrSummary['testMAE'].mean(),2)))\n",
        "print('average testing MAPE:' + str(round(regrSummary['testMAPE'].mean(),2)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iopMpaOzG3DG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot prediction results for a product (UPC)\n",
        "upc = productList[1]\n",
        "data_y = salesCereals.loc[salesCereals['UPC']==upc]['UNITS'].values\n",
        "data_x = salesCereals.loc[salesCereals['UPC']==upc][feature_list].values\n",
        "plot_data_scatter(data_x, data_y, X_test[upc], y_pred[upc], feature_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCn-K6OOKex6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "upc = productList[1]\n",
        "input_x = []\n",
        "prices = [2.0, 2.25, 2.5, 2.75, 3.0, 3.25, 3.5, 3.75, 4.0]\n",
        "\n",
        "# generate inputs for the plot using simple feature values and varying price points\n",
        "for p in prices:\n",
        "  input_x.append([p, p**2, 0,0,0, 1.0])\n",
        "  \n",
        "# obtain the predicted demands\n",
        "predict_y = regr[upc].predict(input_x)\n",
        "plt.plot(prices, predict_y, marker='o')\n",
        "plt.xlabel('Price')\n",
        "plt.ylabel('Demand') \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pUIT5AIn_2gy"
      },
      "source": [
        "# Block 4: Model selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-1CjAbsg_2gz"
      },
      "source": [
        "By comparing the average result, we can see that the linear regression model generally outperformed the decision tree regression and did not overfit the data. Therefore, we proceed with the linear regression model for the whole dataset by replacing 'X_train' with 'X'. Given that the model has 'seen' the whole dataset, its forecast errors normally decrease. Therefore, we will save the trained model and use it for the new data which will be used in the optimization models in the next session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYJ4WZyW2O6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Best model\n",
        "regr = {}\n",
        "regrSummary = pandas.DataFrame(columns=['totalMAE','totalMAPE', 'totalRMSE'], index = productList)\n",
        "\n",
        "for upc in productList:\n",
        "    regr[upc] = sklearn.linear_model.LinearRegression().fit(X[upc],y[upc])\n",
        "    y_pred[upc] = regr[upc].predict(X[upc])\n",
        "    testMAE = sklearn.metrics.mean_absolute_error(y[upc], y_pred[upc])\n",
        "    testMAPE = numpy.mean(numpy.abs((y[upc] - y_pred[upc]) / y[upc]))\n",
        "    testRMSE = numpy.sqrt(sklearn.metrics.mean_squared_error(y[upc], y_pred[upc]))\n",
        "    regrSummary.loc[upc] =  [testMAE, testMAPE, testRMSE]\n",
        "\n",
        "print('Best Model Summary')\n",
        "print(regrSummary)\n",
        "print('average overall MAE:' + str(round(regrSummary['totalMAE'].mean(),2)))\n",
        "print('average overall MAPE:' + str(round(regrSummary['totalMAPE'].mean(),2)))\n",
        "print('average overall RMSE:' + str(round(regrSummary['totalRMSE'].mean(),2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsJ0pDjnrnKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we need to remount Google Drive in order to save into it\n",
        "import pickle\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "cwd = '/content/drive/My Drive/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF5XjbHAmVYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the models to drive\n",
        "for upc in productList:\n",
        "    filename = cwd+str(upc)+'_demand_model.sav'\n",
        "    # save the model to disk\n",
        "    pickle.dump(regr[upc], open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}